"use strict";(self.webpackChunkcocossim_docs=self.webpackChunkcocossim_docs||[]).push([[40],{2942:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"guides/systolic-arrays","title":"Systolic Arrays Deep Dive","description":"This guide provides detailed information about systolic array implementation and execution modes in COCOSSim.","source":"@site/docs/guides/systolic-arrays.md","sourceDirName":"guides","slug":"/guides/systolic-arrays","permalink":"/cocossim-docs/docs/guides/systolic-arrays","draft":false,"unlisted":false,"editUrl":"https://github.com/mc186/cocossim/tree/main/docs/guides/systolic-arrays.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Architecture Overview","permalink":"/cocossim-docs/docs/guides/architecture"},"next":{"title":"Core Classes API Reference","permalink":"/cocossim-docs/docs/api/core-classes"}}');var r=i(4848),t=i(8453);const l={},a="Systolic Arrays Deep Dive",o={},c=[{value:"Overview",id:"overview",level:2},{value:"Execution Modes",id:"execution-modes",level:2},{value:"Weight Stationary (WS) Mode",id:"weight-stationary-ws-mode",level:3},{value:"Advantages",id:"advantages",level:4},{value:"State Machine Flow",id:"state-machine-flow",level:4},{value:"Detailed State Transitions",id:"detailed-state-transitions",level:4},{value:"Tiling Strategy",id:"tiling-strategy",level:4},{value:"Output Stationary (OS) Mode",id:"output-stationary-os-mode",level:3},{value:"Advantages",id:"advantages-1",level:4},{value:"State Machine Flow",id:"state-machine-flow-1",level:4},{value:"Detailed State Transitions",id:"detailed-state-transitions-1",level:4},{value:"Tiling Strategy",id:"tiling-strategy-1",level:4},{value:"Performance Characteristics",id:"performance-characteristics",level:2},{value:"WS vs OS Trade-offs",id:"ws-vs-os-trade-offs",level:3},{value:"When to Use Each Mode",id:"when-to-use-each-mode",level:3},{value:"Buffer Management",id:"buffer-management",level:2},{value:"Buffer Size Calculations",id:"buffer-size-calculations",level:3},{value:"WS Mode Buffer Requirements",id:"ws-mode-buffer-requirements",level:4},{value:"Buffer Overflow Handling",id:"buffer-overflow-handling",level:4},{value:"Multi-Core Parallelism",id:"multi-core-parallelism",level:2},{value:"Tensor Parallelism Strategy",id:"tensor-parallelism-strategy",level:3},{value:"Core-Specific Scheduling",id:"core-specific-scheduling",level:3},{value:"Job Assignment",id:"job-assignment",level:4},{value:"Independent Execution",id:"independent-execution",level:4},{value:"Advanced Features",id:"advanced-features",level:2},{value:"Configurable Array Sizes",id:"configurable-array-sizes",level:3},{value:"Dynamic Execution Mode Selection",id:"dynamic-execution-mode-selection",level:3},{value:"Debugging and Analysis",id:"debugging-and-analysis",level:2},{value:"VCD Waveform Analysis",id:"vcd-waveform-analysis",level:3},{value:"Performance Debugging",id:"performance-debugging",level:3},{value:"Low Utilization Diagnosis",id:"low-utilization-diagnosis",level:4},{value:"Memory Bottleneck Detection",id:"memory-bottleneck-detection",level:4},{value:"Best Practices",id:"best-practices",level:2},{value:"Workload Design",id:"workload-design",level:3},{value:"Multi-Core Efficiency",id:"multi-core-efficiency",level:3},{value:"Performance Tuning",id:"performance-tuning",level:3},{value:"See Also",id:"see-also",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"systolic-arrays-deep-dive",children:"Systolic Arrays Deep Dive"})}),"\n",(0,r.jsx)(n.p,{children:"This guide provides detailed information about systolic array implementation and execution modes in COCOSSim."}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"Systolic arrays are specialized hardware accelerators optimized for matrix multiplication operations, which form the computational core of neural network inference and training."}),"\n",(0,r.jsx)(n.h2,{id:"execution-modes",children:"Execution Modes"}),"\n",(0,r.jsx)(n.p,{children:"COCOSSim supports two primary execution modes that reflect real hardware implementations:"}),"\n",(0,r.jsx)(n.h3,{id:"weight-stationary-ws-mode",children:"Weight Stationary (WS) Mode"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Concept"}),": Weights remain stationary in the processing elements while activations flow through the array."]}),"\n",(0,r.jsx)(n.h4,{id:"advantages",children:"Advantages"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Lower Weight Memory Traffic"}),": Weights loaded once per tile"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Higher Compute Efficiency"}),": Good for compute-bound workloads"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Better for Small Batch Sizes"}),": Efficient weight reuse"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"state-machine-flow",children:"State Machine Flow"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"prefetch \u2192 read \u2192 shift \u2192 write \u2192 (next tile)\n"})}),"\n",(0,r.jsx)(n.h4,{id:"detailed-state-transitions",children:"Detailed State Transitions"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"1. Prefetch State"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"case prefetch:\n  // Load weights into systolic array\n  state_transfer(read, 0, 0, sj->M * max(systolic_fpu_latency, batch_size));\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Purpose"}),": Pre-load weight matrix into systolic array PEs"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Duration"}),": ",(0,r.jsx)(n.code,{children:"M * max(systolic_fpu_latency, batch_size)"})," cycles"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Memory"}),": No additional memory operations (weights pre-loaded)"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"2. Read State"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"case read:  \n  // Read input activations\n  state_transfer(shift, \n                min(sz, sj->K) * min(sz, sj->N) * data_type_width,\n                0,\n                sz * max(systolic_fpu_latency, batch_size));\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Purpose"}),": Read activation data from memory"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Memory Read"}),": ",(0,r.jsx)(n.code,{children:"min(sz, K) * min(sz, N) * data_type_width"})," bytes"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Duration"}),": ",(0,r.jsx)(n.code,{children:"sz * max(systolic_fpu_latency, batch_size)"})," cycles"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"3. Shift State"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"case shift: {\n  // Compute phase: shift data through systolic array\n  int amt_to_write = 0, amt_to_read = 0;\n  \n  if (col_i == loop_cols_tiles) {\n    if (row_i == loop_row_tiles) {\n      amt_to_write = sj->M * sj->N * data_type_width * batch_size;\n    } else {\n      // Preload activations for next row\n      amt_to_read = min(sz, sj->K) * sj->M * batch_size * data_type_width;\n    }\n  }\n  state_transfer(write, amt_to_read, amt_to_write, 0);\n}\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Purpose"}),": Perform matrix multiplication computation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Computation"}),": Data flows through systolic array, accumulating partial products"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Memory"}),": Conditional reads for next tile, writes when tile complete"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"4. Write State"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"case write: {\n  int rd_cycles = sj->M * max(systolic_fpu_latency, batch_size);\n  \n  if (col_i == loop_cols_tiles) {\n    if (row_i == loop_row_tiles) {\n      // Job completed\n      state_transfer(idle, 0, 0, 0);\n      TO_IDLE_CLEANUP();\n    } else {\n      // Move to next row tile\n      j->addr = j->addr_hold;\n      state_transfer(read, 0, 0, rd_cycles);\n      col_i = 1; row_i++;\n    }\n  } else {\n    // Move to next column tile\n    state_transfer(read, 0, 0, rd_cycles);\n    col_i++;\n  }\n}\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Purpose"}),": Write output data to memory and manage tiling"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Memory Write"}),": Output partial sums or final results"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Control Flow"}),": Advance to next tile or complete job"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"tiling-strategy",children:"Tiling Strategy"}),"\n",(0,r.jsxs)(n.p,{children:["WS mode uses ",(0,r.jsx)(n.strong,{children:"column-major tiling"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Matrix C = A \xd7 B\n\nFor row_tiles in range(ceil(M/sz)):\n  For col_tiles in range(ceil(N/sz)):\n    Load weights B[col_tile] into systolic array\n    For k_tiles in range(ceil(K/sz)):  \n      Read activations A[row_tile, k_tile]\n      Compute and accumulate C[row_tile, col_tile]\n    Write C[row_tile, col_tile] to memory\n"})}),"\n",(0,r.jsx)(n.h3,{id:"output-stationary-os-mode",children:"Output Stationary (OS) Mode"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Concept"}),": Output partial sums remain stationary while both weights and activations flow through."]}),"\n",(0,r.jsx)(n.h4,{id:"advantages-1",children:"Advantages"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Lower Output Memory Traffic"}),": Accumulate results in-place"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Better for Large Batch Sizes"}),": Efficient output reuse"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Streaming Friendly"}),": Continuous data flow"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"state-machine-flow-1",children:"State Machine Flow"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"read \u2192 shift \u2192 write \u2192 (next tile)\n"})}),"\n",(0,r.jsx)(n.h4,{id:"detailed-state-transitions-1",children:"Detailed State Transitions"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"1. Read State"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"case read:\n  // Read weights and activations\n  state_transfer(shift, 0, 0, sz * min(systolic_fpu_latency, batch_size));\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Purpose"}),": Read both weights and activations for current tile"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Duration"}),": ",(0,r.jsx)(n.code,{children:"sz * min(systolic_fpu_latency, batch_size)"})," cycles"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Memory"}),": Load data for current computation tile"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"2. Shift State"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"case shift:\n  // Compute and accumulate outputs  \n  state_transfer(write, 0, beats_per_wb, 0);\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Purpose"}),": Perform computation while accumulating in output registers"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Computation"}),": Matrix multiply with in-place accumulation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Memory Write"}),": ",(0,r.jsx)(n.code,{children:"beats_per_wb"})," prepared for writeback"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"3. Write State"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"case write:\n  if (col_i == loop_cols_tiles) {\n    if (row_i == loop_row_tiles) {\n      // Job completed\n      state_transfer(idle, 0, 0, 0);\n      TO_IDLE_CLEANUP();\n    } else {\n      // Move to next row tile  \n      init_row_loop(true);\n      j->addr = j->addr_hold;\n      UPDATE_STATE(read);\n    }\n  } else {\n    // Continue with next column tile\n    state_transfer(read, 0, 0, rd_cycles);\n    col_i++;\n  }\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Purpose"}),": Write accumulated partial sums, manage tiling progression"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Memory"}),": Write partial or final accumulated results"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Control"}),": Advance through tile iterations"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"tiling-strategy-1",children:"Tiling Strategy"}),"\n",(0,r.jsxs)(n.p,{children:["OS mode uses ",(0,r.jsx)(n.strong,{children:"row-major tiling"})," with accumulation:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Matrix C = A \xd7 B (C starts as zeros)\n\nFor row_tiles in range(ceil(M/sz)):\n  For col_tiles in range(ceil(N/sz)):\n    Load partial sums C[row_tile, col_tile]\n    For k_tiles in range(ceil(K/sz)):\n      Read weights B[k_tile, col_tile] \n      Read activations A[row_tile, k_tile]\n      Compute and accumulate into C[row_tile, col_tile]\n    Write updated C[row_tile, col_tile] to memory\n"})}),"\n",(0,r.jsx)(n.h2,{id:"performance-characteristics",children:"Performance Characteristics"}),"\n",(0,r.jsx)(n.h3,{id:"ws-vs-os-trade-offs",children:"WS vs OS Trade-offs"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Aspect"}),(0,r.jsx)(n.th,{children:"Weight Stationary (WS)"}),(0,r.jsx)(n.th,{children:"Output Stationary (OS)"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Weight Traffic"})}),(0,r.jsx)(n.td,{children:"Low (load once per tile)"}),(0,r.jsx)(n.td,{children:"High (load per k-tile)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Activation Traffic"})}),(0,r.jsx)(n.td,{children:"High (load per tile)"}),(0,r.jsx)(n.td,{children:"High (load per tile)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Output Traffic"})}),(0,r.jsx)(n.td,{children:"Medium (write per tile)"}),(0,r.jsx)(n.td,{children:"Low (accumulate in-place)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Memory Bandwidth"})}),(0,r.jsx)(n.td,{children:"Activation-limited"}),(0,r.jsx)(n.td,{children:"Weight-limited"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Small Batch"})}),(0,r.jsx)(n.td,{children:"Better"}),(0,r.jsx)(n.td,{children:"Worse"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Large Batch"})}),(0,r.jsx)(n.td,{children:"Worse"}),(0,r.jsx)(n.td,{children:"Better"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Compute Utilization"})}),(0,r.jsx)(n.td,{children:"Higher"}),(0,r.jsx)(n.td,{children:"Lower (due to accumulation overhead)"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"when-to-use-each-mode",children:"When to Use Each Mode"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Use Weight Stationary (WS) when"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Small to medium batch sizes (1-32)"}),"\n",(0,r.jsx)(n.li,{children:"Weight matrices fit comfortably in on-chip storage"}),"\n",(0,r.jsx)(n.li,{children:"Activation data has good spatial locality"}),"\n",(0,r.jsx)(n.li,{children:"Compute-bound workloads (high arithmetic intensity)"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Use Output Stationary (OS) when"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Large batch sizes (64+)"}),"\n",(0,r.jsx)(n.li,{children:"Output matrices are large and reused"}),"\n",(0,r.jsx)(n.li,{children:"Memory bandwidth is the primary bottleneck"}),"\n",(0,r.jsx)(n.li,{children:"Streaming data scenarios"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"buffer-management",children:"Buffer Management"}),"\n",(0,r.jsx)(n.h3,{id:"buffer-size-calculations",children:"Buffer Size Calculations"}),"\n",(0,r.jsx)(n.h4,{id:"ws-mode-buffer-requirements",children:"WS Mode Buffer Requirements"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"// Per core buffer requirement in WS mode\nint required_buff_sz_per_core = (M * core_n + M * min(K, sa_sz_allo)) * batch_size * data_type_width;\n\nbool core_is_bufferable = required_buff_sz_per_core <= buffer_size_bytes;\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Components"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Output Buffer"}),": ",(0,r.jsx)(n.code,{children:"M * core_n * batch_size * data_type_width"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Activation Buffer"}),": ",(0,r.jsx)(n.code,{children:"M * min(K, sa_sz_allo) * batch_size * data_type_width"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Weight Buffer"}),": Assumed to fit in systolic array storage"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"buffer-overflow-handling",children:"Buffer Overflow Handling"}),"\n",(0,r.jsx)(n.p,{children:"When buffers are insufficient, COCOSSim automatically tiles:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"if (!core_is_bufferable) {\n  // Calculate maximum bufferable output dimension\n  float new_N_f = (float) buffer_size_bytes / (data_type_width * M * batch_size) - sa_sz_allo;\n  int N_per_job = max(1, (int) floor(new_N_f));\n  int num_sequential_jobs = (core_n + N_per_job - 1) / N_per_job;\n  \n  // Create multiple sequential jobs for this core\n  for (int i = 0; i < num_sequential_jobs; ++i) {\n    int current_N = min(N_per_job, remaining_N);\n    auto job = new SysArrayJob(M, K, current_N);\n    job->core_id = core;\n    job->task_idx = core_task_counters[core]++;\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"multi-core-parallelism",children:"Multi-Core Parallelism"}),"\n",(0,r.jsx)(n.h3,{id:"tensor-parallelism-strategy",children:"Tensor Parallelism Strategy"}),"\n",(0,r.jsxs)(n.p,{children:["COCOSSim implements ",(0,r.jsx)(n.strong,{children:"N-dimension splitting"})," for tensor parallelism:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"// Split output dimension across cores\nint core_n = N / n_cores;\n\n// Each core processes independent slice of output\nCore 0: processes output[:, 0:core_n]\nCore 1: processes output[:, core_n:2*core_n] \n...\nCore n: processes output[:, n*core_n:(n+1)*core_n]\n"})}),"\n",(0,r.jsx)(n.h3,{id:"core-specific-scheduling",children:"Core-Specific Scheduling"}),"\n",(0,r.jsx)(n.h4,{id:"job-assignment",children:"Job Assignment"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"// Jobs assigned to specific cores for true parallelism\nfor (int core = 0; core < n_cores; ++core) {\n  auto job = new SysArrayJob(M, K, core_n);\n  job->core_id = core;  // Explicit core assignment\n  job->task_idx = core_task_counters[core]++;  // Per-core task sequence\n}\n"})}),"\n",(0,r.jsx)(n.h4,{id:"independent-execution",children:"Independent Execution"}),"\n",(0,r.jsx)(n.p,{children:"Each core maintains:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Independent Job Queue"}),": ",(0,r.jsx)(n.code,{children:"core_queues[core_idx]"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Separate Task Counters"}),": ",(0,r.jsx)(n.code,{children:"core_task_counters[core]"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Private Memory Addresses"}),": Non-overlapping address spaces"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Autonomous Scheduling"}),": No inter-core synchronization required"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"advanced-features",children:"Advanced Features"}),"\n",(0,r.jsx)(n.h3,{id:"configurable-array-sizes",children:"Configurable Array Sizes"}),"\n",(0,r.jsx)(n.p,{children:"COCOSSim supports various systolic array configurations:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"// Common configurations\nsa_sz_allo = 64;   // 64x64 array (4K PEs)\nsa_sz_allo = 128;  // 128x128 array (16K PEs)  \nsa_sz_allo = 256;  // 256x256 array (64K PEs)\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Scaling Behavior"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Larger Arrays"}),": Higher peak throughput, may have lower utilization"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Smaller Arrays"}),": Better utilization, more memory traffic due to tiling"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"dynamic-execution-mode-selection",children:"Dynamic Execution Mode Selection"}),"\n",(0,r.jsx)(n.p,{children:"Future versions could support dynamic mode selection:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"// Hypothetical dynamic selection logic\nExecutionMode select_mode(int M, int K, int N, int batch_size) {\n  float weight_reuse = (float)(M * N) / K;\n  float output_reuse = (float)(K * N) / M;\n  \n  if (batch_size <= 32 && weight_reuse > 4.0) {\n    return WEIGHT_STATIONARY;\n  } else if (batch_size >= 64 && output_reuse > 2.0) {\n    return OUTPUT_STATIONARY; \n  } else {\n    return WEIGHT_STATIONARY;  // Default\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"debugging-and-analysis",children:"Debugging and Analysis"}),"\n",(0,r.jsx)(n.h3,{id:"vcd-waveform-analysis",children:"VCD Waveform Analysis"}),"\n",(0,r.jsx)(n.p,{children:"Generate detailed execution traces:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cmake -DVCD=ON .. && make\n./cocossim workload.txt  # Generates out.vcd\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Key Signals to Monitor"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"SYSTOLIC_ARRAY_*_STATE"}),": State machine progression"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"SYSTOLIC_ARRAY_*_IDLE_FROM_MEMORY"}),": Memory stall detection"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"SYSTOLIC_ARRAY_*_JOB_IDX"}),": Job assignment tracking"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"performance-debugging",children:"Performance Debugging"}),"\n",(0,r.jsx)(n.h4,{id:"low-utilization-diagnosis",children:"Low Utilization Diagnosis"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Check for memory stalls\ngrep "IDLE_FROM_MEMORY" out.vcd | wc -l\n\n# Analyze state distribution  \ngrep "STATE" out.vcd | awk \'{print $3}\' | sort | uniq -c\n'})}),"\n",(0,r.jsx)(n.h4,{id:"memory-bottleneck-detection",children:"Memory Bottleneck Detection"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# High DRAM commands per cycle indicates memory bound\n./cocossim workload.txt | awk '\n/Cycles/ { cycles = $2 }\n/DRAM CMDs/ { dram = $5 }\nEND { print \"Memory Intensity:\", dram/cycles }'\n"})}),"\n",(0,r.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,r.jsx)(n.h3,{id:"workload-design",children:"Workload Design"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Match Mode to Workload"}),": Use WS for small batches, OS for large batches"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Consider Buffer Constraints"}),": Design layer sizes to fit in available buffers"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Optimize for Reuse"}),": Maximize weight/output reuse patterns"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"multi-core-efficiency",children:"Multi-Core Efficiency"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Ensure Sufficient Parallelism"}),": N dimension should be >> number of cores"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Balance Memory Bandwidth"}),": Avoid memory bottlenecks with too many cores"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Monitor Per-Core Utilization"}),": Check that all cores are active"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"performance-tuning",children:"Performance Tuning"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Profile Different Array Sizes"}),": Find optimal size for your workloads"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compare Execution Modes"}),": Test both WS and OS for each workload type"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Analyze Memory Patterns"}),": Optimize for memory locality and bandwidth"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"see-also",children:"See Also"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/cocossim-docs/docs/guides/architecture",children:"Architecture Guide"})," - High-level system design overview"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/cocossim-docs/docs/guides/basic-usage",children:"Basic Usage Guide"})," - Getting started with simulations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/cocossim-docs/docs/api/core-classes",children:"Core Classes API"})," - Programming interface details"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>a});var s=i(6540);const r={},t=s.createContext(r);function l(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);